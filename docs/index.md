---
title:  "home"
layout: splash
classes: wide
permalink: "/"
comments: true
---

<div class="image-container">
  <img src="{{ '/assets/images/albee_main.png' | relative_url }}"
       class="responsive-image"
       style="max-height: 300px; width: auto; height: auto;">
</div>

I'm a Robotics Technologist in the Maritime and Multi-Agent Autonomy group at NASA's Jet Propulsion Laboratory, California Institute of Technology. I am broadly interested in autonomy for mobile robotic systems operating in challenging environments: often this means operating in situations that are *uncertain, unknown, or unstructured*. Increasingly, this also means seeking out safety guarantees, learning-based solutions, and real-time performance on resource-constrained embedded platforms. The overarching goal is to make autonomous robotic operations safer and more efficient when human-in-the-loop operation becomes infeasible, risky, or wasteful.

This often involves extending and inventing new tools from **optimal control**, **numerical optimization**, **reinforcement learning**, **machine learning**, **motion planning**, and their interplay with **state estimation, localization, and perception**. You can learn a bit more in my [about](/about/) page. I am particularly excited about:

* Infusing learning-based tools into planning and control to improve efficiency and safety under imperfect knowledge.
* Providing or enhancing safety guarantees for uncertain dynamical systems, including when new information is revealed online.
* Considering perception, localization, and "information gain" explicitly in robotic planning.
* Autonomy frameworks incorporating the above for exploration, space, and other extreme environment robotics applications.


---
